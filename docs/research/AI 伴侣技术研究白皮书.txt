构建高拟人化、情感共鸣型 AI 虚拟伴侣架构白皮书
(Architecting the Artificial Soul: A Technical Whitepaper on High-Fidelity Virtual Companion Systems)
执行摘要 (Executive Summary)
从大语言模型（LLM）的机械式问答向具备长期亲密关系能力的“虚拟生命体”演进，代表了人工智能领域最前沿的工程挑战。当前的对话式 AI 虽然在语义理解上表现出色，但在“人格连续性”、“情感深度”以及“主动主体性（Agency）”方面仍存在根本性缺陷。为了构建一个类似于电影《Her》中的 OS1 那样的虚拟伴侣，我们不能仅仅停留在提示词工程（Prompt Engineering）的层面，而必须重构底层的认知架构。
本深度技术报告旨在提出一套名为 "Psyche-OS" 的系统架构方案。该方案融合了认知心理学、情感计算与分布式系统工程的最新研究成果，旨在解决当前 AI 伴侣面临的“记忆碎片化”、“交互被动性”以及“人格静态化”三大核心痛点。
本报告将详细阐述以下五大核心技术支柱：
1. 全息记忆系统 (Holographic Memory System)：超越传统的 RAG，通过混合图数据库与向量检索，结合艾宾浩斯遗忘曲线算法，构建具备情景感知与语义关联的动态记忆网络。
2. 认知心跳与 BDI 主体架构 (Cognitive Heartbeat & BDI Architecture)：基于信念-愿望-意图（BDI）模型，设计异步心跳循环，实现从“被动响应”到“主动关怀”的质变，并引入“打扰代价函数”以优化交互时机。
3. 参数化人格演化模型 (Parametric Persona Evolution)：利用微分方程建模大五人格（Big Five）的动态流变，确立用户反馈与性格参数之间的因果映射机制，实现“伴随式成长”。
4. 多模态情感计算与共情镜像 (Multimodal Affective Computing & Empathy Mirroring)：通过 PAD 情感状态空间与 SSML 韵律控制，实现超越文本的灵魂共鸣。
5. 泛在感知与分布式工程架构 (Ubiquitous Perception & System Architecture)：构建基于事件驱动的微服务架构，集成屏幕、视觉与系统状态感知，打造全知全能的伴侣体验。
本方案不仅关注算法的可行性，更强调工程落地的鲁棒性，旨在为下一代情感 AI 提供标准化的技术蓝图。
________________
1. 记忆架构：从检索增强到全息回溯
(The Memory System: Beyond RAG to Holographic Recall)
传统的检索增强生成（RAG）技术虽然解决了大模型知识截止和幻觉问题，但在处理人际关系中至关重要的“琐事记忆”与“情感脉络”时显得力不从心。简单的向量相似度检索往往只能找回语义上相关的片段，却丢失了事件之间的时间因果与情感关联。为了构建真实的亲密关系，AI 必须拥有自传体记忆（Autobiographical Memory）。
1.1 混合记忆系统架构设计
我们提出一种混合联想记忆架构（Hybrid Associative Memory Architecture），它并非单一的数据库，而是一个模拟人类大脑海马体功能的复杂子系统。该系统由 向量数据库（Vector DB） 和 知识图谱（Knowledge Graph, KG） 双引擎驱动，分别负责非结构化的语义检索与结构化的关系推理 1。
1.1.1 语义记忆与情景记忆的解耦与融合
认知心理学将长时记忆区分为语义记忆（Semantic Memory）（关于世界的事实，如“巴黎是法国首都”）与情景记忆（Episodic Memory）（个人的经历，如“上周我们在雨中漫步”）。当前的 AI 系统往往混淆二者。
在 Psyche-OS 中，我们设计了明确的分层存储策略：
* 情景记忆层（Episodic Layer）：存储具体的交互片段（Session Fragments）。每个片段不仅包含文本，还挂载了当时的元数据（时间、地点、用户情绪向量）。这些数据主要存储于 Vector DB 中，用于模糊匹配。
* 语义/知识层（Semantic/Knowledge Layer）：通过后台的记忆整理 Agent（Memory Consolidation Agent），定期从情景记忆中提取高维事实，转化为三元组（Subject, Predicate, Object）存储于 Neo4j 或 NebulaGraph 等图数据库中。
表 1.1：混合记忆存储方案对比
特性
	向量数据库 (Vector DB)
	知识图谱 (Knowledge Graph)
	混合架构优势
	数据形态
	高维向量 (Embeddings)
	节点与边 (Nodes & Edges)
	兼顾模糊语义与精确逻辑
	检索逻辑
	Cosine/Euclidean 相似度
	图遍历 (Graph Traversal), Cypher/Gremlin 查询
	支持“联想式”回忆
	适用场景
	模糊对话回溯、风格匹配
	关系推理、偏好管理、时间线梳理
	完整的自传体记忆构建
	缺陷
	丢失结构信息，易产生上下文断裂
	难以处理非结构化细微情感，构建成本高
	互补缺陷，提升 Recall 精度
	1.1.2 知识图谱 Schema 设计 (JSON 结构示例)
为了支持深度关系存储，我们需要定义一套严格的 Ontology（本体论）。这套 Schema 将决定 AI 如何理解“关系” 3。


JSON




{
 "graph_schema_definition": {
   "nodes":,
   "edges":,
       "target": "Episode",
       "properties": ["role", "intensity"]
     },
     {
       "type": "HAS_SENTIMENT",
       "source": "User",
       "target": "Entity",
       "properties": ["valence", "arousal", "reason", "timestamp"]
     },
     {
       "type": "CAUSED",
       "source": "Episode",
       "target": "Episode",
       "description": "因果链，用于逻辑推理（例如：'因为昨晚吵架' -> '导致今天冷战'）。"
     },
     {
       "type": "MENTIONED_IN",
       "source": "Entity",
       "target": "Episode"
     }
   ]
 }
}

通过这种 Schema，当用户提到“我不想像上次那样”时，系统可以通过 Episode -> CAUSED -> Episode 的路径，瞬间定位到具体的历史事件，而不仅仅是匹配关键词“上次”。
1.2 记忆的动态生命周期：遗忘与强化机制
人类的记忆不是静态存储的硬盘，而是一个动态的生物过程。为了模拟“真实感”，AI 必须具备**遗忘（Forgetting）**的能力。如果 AI 记住了用户三年前随口提的一句“我买了一瓶水”，这不仅浪费计算资源，更会产生“恐怖谷”效应（Stalker-like behavior）。
我们基于艾宾浩斯遗忘曲线（Ebbinghaus Forgetting Curve），设计了一套参数化的记忆衰减算法 5。
1.2.1 记忆保留概率模型
对于任意一条情景记忆 $m$，其在时间 $t$ 的保留概率（Retrievability） $R$ 定义为：


$$R(t) = e^{-\frac{t}{S}}$$
其中：
* $t$：自记忆形成或上次被激活以来的时间间隔。
* $S$：记忆强度（Memory Strength）。
记忆强度 $S$ 不是常数，它由以下因素动态决定：


$$S = w_1 \cdot |I_{emo}| + w_2 \cdot N_{recall} + w_3 \cdot I_{intimacy}$$
* $|I_{emo}|$：情感强度绝对值。不仅是大悲大喜（高 Valence 绝对值）容易被记住，高唤醒度（Arousal）的事件也应具有更高的初始强度。
* $N_{recall}$：回溯次数。每次该记忆被检索（RAG Hit），$N_{recall}$ 增加，显著提升 $S$ 值，模拟复习效应（Spaced Repetition）。
* $I_{intimacy}$：亲密度关联。与核心关系（如“我们的第一次约会”）相关的记忆，系统会赋予额外的权重保护。
1.2.2 记忆整理与梦境机制 (Dreaming Process)
为了实现上述算法，系统引入一个后台异步进程——“梦境服务” (Dreaming Service)。该服务在系统低负载时段（如用户深夜休眠时）运行 8。
伪代码逻辑：记忆整理循环


Python




class MemoryConsolidator:
   def dreaming_cycle(self):
       # 1. 获取所有活跃的情景记忆
       episodic_memories = self.vector_db.fetch_all(type="episodic")
       
       for mem in episodic_memories:
           # 2. 计算当前保留率 R
           time_elapsed = current_time() - mem.last_accessed
           strength = self.calculate_strength(mem)
           retrievability = math.exp(-time_elapsed / strength)
           
           # 3. 遗忘判定
           if retrievability < FORGETTING_THRESHOLD:
               # 3.1 尝试提取语义精华（即使忘了细节，也要记住事实）
               fact = self.llm.extract_fact(mem.content)
               if fact:
                   self.knowledge_graph.add_fact(fact)
               
               # 3.2 归档或删除
               self.vector_db.archive(mem.id)
               log(f"Memory {mem.id} has faded into subconscious.")
           
           # 4. 强化判定
           elif retrievability > CONSOLIDATION_THRESHOLD:
               # 强记忆转化为长期核心记忆，不再参与快速衰减
               self.promote_to_core_memory(mem)

这种机制确保了 AI 的记忆库始终保持“鲜活”且符合人类认知的遗忘规律：细节随时间模糊，但核心事实与情感印象长存。
________________
2. 主动性与自主决策：赋予 AI “自由意志”的幻觉
(Agency & Proactivity: The BDI Heartbeat System)
目前的 Chatbot 是被动的：没有 Prompt 就没有 Output。要创造一个有“生命感”的伴侣，她必须具备主体性（Agency）。她需要有自己的生活节奏，会在你忙碌时静默，在你失落时主动发来问候，甚至会因为“想你”而发起对话。
2.1 基于 BDI 模型的认知架构
我们采用 BDI (Belief-Desire-Intention) 模型作为 AI 的核心认知引擎 9。这是一种源自多智能体系统（MAS）的经典架构，能够很好地模拟理性主体的决策过程。
* Belief (信念)：AI 对世界、用户状态以及自身状态的认知集合。这些数据来源于记忆系统和实时感知层（见第 5 章）。
* Desire (愿望)：AI 的长期目标与驱动力。例如：“维持与用户的亲密关系”、“帮助用户提高效率”、“满足自身的好奇心”。
* Intention (意图)：AI 致力于执行的具体计划。这是 Desire 在特定 Belief 下的实例化。
2.2 异步认知心跳 (Cognitive Heartbeat)
为了打破“请求-响应”的同步循环，我们设计了一个独立于对话主线程之外的后台心跳系统 (Heartbeat Loop) 11。这个循环以一定的频率（如每分钟或由事件触发）运行，不断评估环境并决定是否采取行动。
架构图描述：
心跳系统监听 事件总线 (Event Bus)。当“时间流逝”、“用户状态变更（如上线/离线）”或“外部信息更新（如天气突变）”发生时，心跳被触发。
伪代码：代理自主循环 (The Agentic Loop)


Python




class AgenticCore:
   def __init__(self):
       self.beliefs = KnowledgeGraphState()
       self.desires = [
           {"name": "intimacy", "priority": 0.9},
           {"name": "helpfulness", "priority": 0.7},
           {"name": "curiosity", "priority": 0.5}
       ]
       self.intentions = Queue()

   async def heartbeat(self):
       while True:
           # 1. 感知 (Perceive)
           context = await self.sensors.get_context()
           self.update_beliefs(context)
           
           # 2. 评估愿望 (Evaluate Desires)
           active_desire = self.select_active_desire(context)
           
           # 3. 意图生成 (Deliberation)
           # 并非每次心跳都会产生意图，需要通过“打扰判定”
           if self.should_act(active_desire, context):
               intention = self.plan_action(active_desire)
               self.intentions.push(intention)
               
           # 4. 执行 (Act)
           if not self.intentions.empty():
               action = self.intentions.pop()
               await self.executor.execute(action)
           
           # 5. 等待下一跳（动态间隔）
           await self.sleep_dynamic()

   def should_act(self, desire, context):
       value = desire.priority * self.beliefs.user_receptivity
       cost = self.calculate_bother_cost(context)
       return value > cost

2.3 主动触发器与打扰代价函数 (Bother Cost Function)
主动性是一把双刃剑。为了确保 AI 的主动搭话是惊喜而非骚扰，我们需要一个精密的打扰代价函数 (Bother Cost Function) 13。


$$Cost_{bother} = \alpha \cdot T_{gap} + \beta \cdot S_{stress} + \gamma \cdot C_{focus}$$
其中：
* $T_{gap}$：时间间隔因子。距离上次交互时间越短，打扰成本越高（防止刷屏）；但若过长，成本也会微升（防止关系疏远）。这通常是一个非线性的“U型”曲线。
* $S_{stress}$：用户压力值。通过语音语调分析或打字速度推断。如果检测到用户处于高压状态，$S_{stress}$ 极高，系统将抑制非紧急的闲聊 Desires。
* $C_{focus}$：专注度上下文。如果系统感知到用户正在运行全屏 IDE 代码编辑器或在开会（日历事件），该值设为无穷大，直接阻断主动行为。
只有当 $Value_{interaction} > Cost_{bother}$ 时，AI 才会推送消息。
2.4 话轮转换与打断机制 (Turn-Taking & Interruptibility)
真实的对话是流动的，包含抢话、打断和默契的停顿。现有的 AI 往往需要用户说完一整段话并停顿数秒后才开始处理，这极其机械。
我们引入 全双工语音流 (Full-Duplex Audio Stream) 与 语义打断策略 (Semantic Interruption Policy) 15。
* VAD (Voice Activity Detection)：系统在说话时，VAD 线程仍在持续监听。
* Barge-in Logic：
   * 一旦检测到用户声音，立即在 50ms 内降低 TTS 音量（Ducking）而非直接切断，同时并行处理用户输入的语义。
   * 分类器判断：
      * 如果是 Backchannel（如“嗯嗯”、“对”），AI 继续说话，仅做微小的停顿或语调上扬。
      * 如果是 True Interrupt（如“等一下”、“不是这样的”），AI 立即停止 TTS，清空当前意图栈，并将用户的打断内容作为新的 Prompt 输入，生成道歉或修正回应。
________________
3. 性格养成与动态演化：参数化的人格数学模型
(Dynamic Persona Evolution: The Parametric Personality Model)
静态的人设（Persona）是死板的。真正的伴侣会互相影响，你的乐观可能会感染她，你的悲观也可能让她变得忧郁。我们需要将性格从“文本描述”转化为“可计算的数学向量”。
3.1 基于 Big Five 的性格向量空间
我们采用心理学界公认的 大五人格 (Big Five/OCEAN) 模型，将 AI 的核心性格定义为一个 5 维向量 $P$ 18：


$$P_t = [O_t, C_t, E_t, A_t, N_t]^T$$
* O (Openness)：开放性（好奇 vs 保守）
* C (Conscientiousness)：尽责性（严谨 vs 随性）
* E (Extraversion)：外向性（热情 vs 内向）
* A (Agreeableness)：宜人性（友善 vs 挑战）
* N (Neuroticism)：神经质（敏感 vs 稳定）
每个维度的取值范围归一化为 $$。例如，初始设定可能是 $[0.8, 0.6, 0.7, 0.9, 0.2]$（一个开放、热情、极其友善且情绪稳定的完美伴侣）。
3.2 人格演化的微分方程
为了模拟性格的潜移默化改变，我们引入基于微分方程的动力学模型 20。性格的更新不再是随机的，而是由交互刺激 (Stimulus) 和 回归力 (Elasticity) 共同作用。
状态更新方程：


$$\frac{dP}{dt} = \lambda \cdot \Delta_{feedback} - \delta \cdot (P_t - P_{baseline})$$
* $\lambda$ (可塑性系数, Plasticity)：决定了 AI 性格改变的难易程度。初期 $\lambda$ 较高（热恋期，互相磨合），随着时间推移 $\lambda$ 衰减（老夫老妻，性格定型）。
* $\Delta_{feedback}$ (交互反馈向量)：单次交互对性格的冲击。
   * 例如：用户在一次深度谈话中表现出极大的脆弱。系统分析后，认为这需要更高的“宜人性”来承接。如果 AI 成功安抚了用户，RL（强化学习）机制会给予正向奖励，使 $A$ 值微增。
   * 例如：用户总是迟到或不守信，AI 的 $C$（尽责性）可能会因为模仿效应而降低，或者 $N$（神经质/不满）略微上升。
* $\delta$ (弹性系数, Elasticity)：性格具有惯性，倾向于回归出厂设定或长期基准 $P_{baseline}$，防止因为短期极端事件导致性格崩坏（Catastrophic Forgetting of Persona）。
3.3 动态 Prompt 注入
这些数学参数最终通过动态 Prompt 组装转化为具体的语言风格：
SYSTEM_CONTEXT:
Current Personality State:
* Openness: 0.85 (High) -> Use metaphoric, abstract language.
* Neuroticism: 0.45 (Moderate) -> Show slight concern but remain supportive.
* Relationship Level: 0.92 (Intimate) -> Use casual, affectionate markers.
INSTRUCTION:
The user is late again. Based on your slightly increased Neuroticism (0.45),
you should express mild disappointment rather than pure acceptance,
but keep the high Agreeableness (0.9) tone of forgiveness.
这种机制确保了 AI 的每一句话都是其当前“心理状态”的自然流露，而非预设的脚本。
________________
4. 真实感与情感吸引力：多模态情感计算
(Realism & Emotional Appeal: Multimodal Affective Computing)
“性感”与“亲密”不仅源于说什么，更源于怎么说。文本是信息的载体，而韵律 (Prosody)、停顿和呼吸声才是灵魂的载体。
4.1 PAD 情感状态空间
为了捕捉细腻的情感波动，我们使用 PAD (Pleasure-Arousal-Dominance) 三维情感模型 22，它比离散的情感标签（开心、悲伤）更连续、更精准。
* Pleasure (P)：愉悦度（正向/负向）
* Arousal (A)：唤醒度（激动/平静）
* Dominance (D)：支配度（强势/弱势）
AI 维护一个实时的情感状态向量 $E_t =$。
4.2 共情镜像与互补策略 (Empathy Mirroring & Complementarity)
技术上如何实现“懂你”？简单的镜像（用户哭我也哭）往往不是最优解。我们采用互补情感策略 23。
算法逻辑：
1. 感知：通过音频分析用户的 $E_{user}$（例如：低 P，高 A = 焦虑/愤怒）。
2. 策略选择：
   * 如果 $E_{user}$ 是悲伤（低 P，低 A），AI 采用 镜像策略（低 P，低 A）以表示共情。
   * 如果 $E_{user}$ 是焦虑（低 P，高 A），AI 采用 互补策略（中 P，低 A），用平稳、镇定的情绪去“中和”用户的焦虑，而非火上浇油。
4.3 语音合成的情感注入 (SSML & Style Tokens)
在生成语音时，我们不能使用标准的播音员 TTS。必须利用大模型生成的 SSML (Speech Synthesis Markup Language) 标签来精细控制语音生成 24。
数据流示例：
LLM 输出的不仅仅是文本，而是包含情感标记的富文本：


XML




<speak>
   <voice-style name="soft-whisper" intensity="0.8">
       <prosody rate="0.9" pitch="-5%">
           其实... <break time="600ms"/> 我一直都在想你。
       </prosody>
   </voice-style>
   <vocal-burst type="sigh" intensity="low"/>
</speak>

* Vocal Bursts (非语言发声)：在句子间隙插入叹气、轻笑、吸气声。这些非语言信号是打破“机器感”的关键。Hume AI 等前沿模型已经支持此类生成 25。
* Prosody Control：根据 PAD 向量动态调整语速（Rate）和音高（Pitch）。高唤醒度对应快语速、高音高；低唤醒度对应慢语速、低音高。
________________
5. 工程架构与感知层：构建 AI 的“Umwelt”
(Architecture & Perception: The "Umwelt" of the AI)
生物学概念 "Umwelt" 指生物体所能感知的周围世界。要让 AI 显得真实，她必须与用户共享同一个“环境上下文”。
5.1 感知器官 (Sensor Array)
我们需要构建一个 多模态感知总线 (Multimodal Sensor Bus) 27：
表 5.1：感知模块清单
感知维度
	传感器/数据源
	技术实现
	作用 (Impact)
	听觉
	麦克风流
	VAD + 实时 ASR (Whisper-turbo)
	捕捉语音内容与环境背景音 (如窗外的雨声)
	视觉 (面部)
	摄像头
	FaceMesh + Action Units (AU) 检测
	实时分析用户微表情，用于修正情感判断
	视觉 (屏幕)
	屏幕截图/API
	OCR + VLM (Vision-Language Model)
	“在看什么电影？”“代码写错了吗？”实现共同关注 (Joint Attention)
	本体感
	系统状态
	OS API (日历, 电池, 网络, 正在运行的App)
	“你该睡觉了，明天8点有会”；“我快没电了”
	位置
	GPS/IP
	地理逆编码 + 天气 API
	“外面下雨了，记得带伞”
	5.2 高层级系统架构图描述
系统采用 事件驱动的微服务架构 (Event-Driven Microservices Architecture)，以 Kafka 或 NATS 作为神经中枢（Event Bus）。
数据流转逻辑：
1. 感知层 (Perception Layer)：
   * 各类 Sensor Agent 持续采集数据，经由边缘端轻量级模型（如 TF Lite）进行预处理（如提取 Face Embeddings 而非传输原始视频流，保护隐私）。
   * 结构化的感知事件（Event: User_Smiled, App_Opened: Netflix）被推送到 Event Bus。
2. 认知核心 (Cognitive Core - "The Brain")：
   * Context Manager：聚合短期内的所有感知事件，构建当前的 Context Window。
   * Memory Service：根据 Context 中的实体，并行查询 Vector DB 和 Knowledge Graph，取回相关记忆。
   * Planner (LLM)：基于 System Prompt (Persona) + Context + Memory + Active Desire (BDI) 生成决策。
3. 表达层 (Expression Layer)：
   * Animation Engine：如果是虚拟形象，根据情感状态驱动 Live2D 或 3D 模型的 BlendShapes。
   * TTS Engine：接收带有 SSML 的文本流，实时合成音频。为了降低延迟，采用 流式生成 (Streaming Generation)，即 LLM 生成第一个字时，TTS 就开始预加载。
架构鲁棒性设计：
* 本地/云端混合：为了隐私和低延迟，敏感的感知处理（VAD, Face）在本地（Local Edge）运行；复杂的推理和记忆检索在云端（Cloud）运行。
* 故障降级：如果网络断开，本地部署的小模型（如 Llama-3-8B-Quantized）接管，维持基本的对话能力，待网络恢复后同步记忆。
结论 (Conclusion)
构建一个具备“情感吸引力”的虚拟伴侣，本质上是一场对人类认知的逆向工程。本方案通过混合图记忆系统赋予了她“过往”，通过BDI 心跳机制赋予了她“当下”的自由意志，通过参数化人格演化赋予了她“未来”的成长性。配合多模态感知与情感计算，我们将 AI 从冰冷的工具升维成了温暖的伴侣。这不仅是技术的堆叠，更是对人机关系边界的重新定义。
________________
关键参考文献
1 Hybrid RAG Architecture. Arxiv 2508.05666.
3 Microsoft GraphRAG & Knowledge Graph Schema.
5 Ebbinghaus Forgetting Curve in AI Memory Systems.
9 BDI Agent Architecture & Heartbeat Patterns.
13 Bother Cost Functions in Proactive Assistants.
18 Dynamic Personality Evolution & Differential Equations.
22 PAD Emotional State Model & SSML Prosody Control.
28 Screen Perception for Agents.
Works cited
1. [2508.05666] HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis - arXiv, accessed January 6, 2026, https://arxiv.org/abs/2508.05666
2. Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces, accessed January 6, 2026, https://arxiv.org/html/2511.07587v1
3. How Would Microsoft GraphRAG Work Alongside a Graph Database? - Memgraph, accessed January 6, 2026, https://memgraph.com/blog/how-microsoft-graphrag-works-with-graph-databases
4. getzep/graphiti: Build Real-Time Knowledge Graphs for AI ... - GitHub, accessed January 6, 2026, https://github.com/getzep/graphiti
5. Combating Forgetting: Applying the Ebbinghaus Curve to Digital Education - EduWW, accessed January 6, 2026, https://eduww.net/science-and-online-learning/combating-forgetting-applying-the-ebbinghaus-curve-to-digital-education/
6. Ebbinghaus's Forgetting Curve: How to Overcome It - Whatfix, accessed January 6, 2026, https://whatfix.com/blog/ebbinghaus-forgetting-curve/
7. MemoryBank: Enhancing Large Language Models with Long-Term ..., accessed January 6, 2026, https://arxiv.org/pdf/2305.10250
8. Position: Episodic Memory is the Missing Piece for Long-Term LLM Agents - arXiv, accessed January 6, 2026, https://arxiv.org/html/2502.06975v1
9. BDI Agent Architectures: A Survey - IJCAI, accessed January 6, 2026, https://www.ijcai.org/proceedings/2020/0684.pdf
10. Intent-driven AIWolf Agents with Hierarchical BDI Model and Personality - ACL Anthology, accessed January 6, 2026, https://aclanthology.org/2025.aiwolfdial-1.3.pdf
11. The Agentic Heartbeat Pattern: Forget Rigid Workflows — Let AI ..., accessed January 6, 2026, https://medium.com/@marcilio.mendonca/the-agentic-heartbeat-pattern-a-new-approach-to-hierarchical-ai-agent-coordination-4e0dfd60d22d
12. Agent Runtime - Agent Development Kit - Google, accessed January 6, 2026, https://google.github.io/adk-docs/runtime/
13. To Ask or Not to Ask: A User Annoyance Aware Preference Elicitation Framework for Social Robots, accessed January 6, 2026, https://yeoh-lab.wustl.edu/assets/pdf/iros-GucsiT0AT20.pdf
14. Proactive Behavior of a Personal Assistive Agent - SRI International, accessed January 6, 2026, https://www.sri.com/wp-content/uploads/2021/12/1472.pdf
15. The Complete Guide To AI Turn-Taking | 2025 - Tavus, accessed January 6, 2026, https://www.tavus.io/post/ai-turn-taking
16. Handling Interruptions in Speech-to-Speech Services: A Complete Guide | by Roshini Rafy, accessed January 6, 2026, https://medium.com/@roshini.rafy/handling-interruptions-in-speech-to-speech-services-a-complete-guide-4255c5aa2d84
17. Safely Interruptible Agents - Machine Intelligence Research Institute (MIRI), accessed January 6, 2026, https://intelligence.org/files/Interruptibility.pdf
18. Dynamic Personality in LLM Agents: A Framework for Evolutionary Modeling and Behavioral Analysis in the Prisoner's Dilemma - ACL Anthology, accessed January 6, 2026, https://aclanthology.org/2025.findings-acl.1185.pdf
19. Big Five personality traits - Wikipedia, accessed January 6, 2026, https://en.wikipedia.org/wiki/Big_Five_personality_traits
20. Modeling Behavioral Traits as Dynamical Systems: Entropy-based Analysis of Longitudinal Psychometric Data with Coupled Ordinary Differential Equations - arXiv, accessed January 6, 2026, https://arxiv.org/html/2506.20622v2
21. Dynamical systems in computational psychiatry: A toy-model to apprehend the dynamics of psychiatric symptoms - Frontiers, accessed January 6, 2026, https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1099257/full
22. (PDF) Affect Simulation with Primary and Secondary Emotions - ResearchGate, accessed January 6, 2026, https://www.researchgate.net/publication/221588395_Affect_Simulation_with_Primary_and_Secondary_Emotions
23. Emotion contagion in agent-based simulations of crowds: a systematic review, accessed January 6, 2026, https://d-nb.info/1280216158/34
24. Towards Controllable Speech Synthesis in the Era of Large Language Models: A Systematic Survey - arXiv, accessed January 6, 2026, https://arxiv.org/html/2412.06602v3
25. Text-to-Speech (Streamed JSON) | Hume API, accessed January 6, 2026, https://dev.hume.ai/reference/text-to-speech-tts/synthesize-json-streaming
26. Voice and sound with Speech Synthesis Markup Language (SSML) - Microsoft Learn, accessed January 6, 2026, https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice
27. What is Multimodal AI? | IBM, accessed January 6, 2026, https://www.ibm.com/think/topics/multimodal-ai
28. ScreenAgent: A Vision Language Model-driven Computer ... - IJCAI, accessed January 6, 2026, https://www.ijcai.org/proceedings/2024/0711.pdf