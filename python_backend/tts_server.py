"""
TTS Server - æµå¼è¯­éŸ³åˆæˆæœåŠ¡
æ”¯æŒå¯æ’æ‹”çš„ TTS å¼•æ“ï¼ˆEdge TTS ä¸ºé»˜è®¤å®ç°ï¼‰
"""
import logging
import json
import re
import os
import time
import asyncio
import subprocess
from typing import Optional, AsyncGenerator
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import httpx

# å¯¼å…¥æœ¬åœ°æ¨¡å—
try:
    from tts_engine_gptsovits import GPTSoVITSEngine
except ImportError:
    from .tts_engine_gptsovits import GPTSoVITSEngine

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç¡®ä¿ FFmpeg (åœ¨ GPT-SoVITS/runtime) åœ¨ PATH ä¸­
def ensure_ffmpeg_path():
    # å‡è®¾ runtime åœ¨ä¸¤çº§ç›®å½•ä¸‹ (ä» python_backend å‘ä¸Š)
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    ffmpeg_dir = os.path.join(base_dir, "GPT-SoVITS", "runtime")
    if os.path.exists(ffmpeg_dir):
        path = os.environ.get("PATH", "")
        if ffmpeg_dir not in path:
            logger.info(f"Adding FFmpeg to PATH: {ffmpeg_dir}")
            os.environ["PATH"] = f"{ffmpeg_dir};{path}"
    else:
        logger.warning(f"FFmpeg binary directory not found at: {ffmpeg_dir}")

ensure_ffmpeg_path()

app = FastAPI(title="Lumina TTS Service")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

edge_tts_engine: Optional[any] = None
gpt_sovits_engine: Optional[any] = None
emotion_style_map = {}

class TTSRequest(BaseModel):
    text: str
    voice: str = "zh-CN-XiaoxiaoNeural"
    emotion: Optional[str] = None
    engine: str = "edge-tts"
    rate: str = "+0%"
    pitch: str = "+0Hz"


# å…¨å±€ HTTP å®¢æˆ·ç«¯ (è¿æ¥å¤ç”¨)
http_client: Optional[httpx.AsyncClient] = None

@app.on_event("startup")
async def startup_event():
    global edge_tts_engine, gpt_sovits_engine, emotion_style_map, http_client
    
    # åˆå§‹åŒ– HTTP å®¢æˆ·ç«¯
    http_client = httpx.AsyncClient(timeout=None) # ä¿æŒé•¿è¿æ¥
    logger.info("Shared HTTP client initialized")

    logger.info("Initializing Edge TTS...")
    try:
        import edge_tts
        edge_tts_engine = edge_tts
    except ImportError:
        logger.error("edge-tts not installed")
    
    logger.info("Initializing GPT-SoVITS...")
    try:
        gpt_sovits_engine = GPTSoVITSEngine()
        logger.info(f"GPT-SoVITS wrapper loaded")
    except Exception as e:
        logger.warning(f"Failed to load GPT-SoVITS wrapper: {e}")

    try:
        map_path = os.path.join(os.path.dirname(__file__), "tts_emotion_styles.json")
        if os.path.exists(map_path):
            with open(map_path, "r", encoding="utf-8") as f:
                emotion_style_map = json.load(f)
        else:
            emotion_style_map = {}
    except Exception as e:
        logger.warning(f"Failed to load emotion map: {e}")
        emotion_style_map = {}

@app.on_event("shutdown")
async def shutdown_event():
    global http_client
    if http_client:
        await http_client.aclose()
        logger.info("Shared HTTP client closed")
    # Clean up subprocesses if any (handled by their own logic usually)

# âš¡ ä¿®å¤: æ·»åŠ è¿æ¥æ± é‡ç½®ç«¯ç‚¹ï¼ˆç”¨äºæ‰‹åŠ¨æ¢å¤ï¼‰
@app.get("/health/reset_pool")
async def reset_connection_pool():
    """æ‰‹åŠ¨é‡ç½® HTTP è¿æ¥æ± ï¼ˆå½“TTSå‡ºç°é—®é¢˜æ—¶ä½¿ç”¨ï¼‰"""
    global http_client
    if http_client:
        await http_client.aclose()
        http_client = httpx.AsyncClient(timeout=None)
        logger.info("[Health] HTTP client pool reset")
        return {"status": "ok", "message": "Connection pool reset"}
    return {"status": "error", "message": "No client to reset"}

def parse_emotion_tags(text: str):
    # 1. Extract first emotion tag for style control
    emotion = None
    # Match standard [emotion] formats
    match = re.search(r"\[([a-zA-Z0-9_-]+)\]", text)
    if match:
        emotion = match.group(1)
        
    # 2. Clean Text for TTS
    # Remove all [tags]
    clean_text = re.sub(r"\[.*?\]", "", text)
    # Remove all (parentheses comments) often used for actions
    clean_text = re.sub(r"\(.*?\)", "", clean_text)
    # Remove markdown bold/italic markers
    clean_text = clean_text.replace("*", "").replace("_", "")
    # Remove excess whitespace
    clean_text = re.sub(r"\s+", " ", clean_text).strip()
    
    return clean_text, emotion



async def transcode_to_aac(pcm_iterator: AsyncGenerator[bytes, None], sample_rate=32000) -> AsyncGenerator[bytes, None]:
    """
    æµå¼è½¬ç : PCM (Stream) -> FFmpeg -> AAC (Stream)
    """
    # å¯åŠ¨ FFmpeg è¿›ç¨‹
    # è¾“å…¥: s16le PCM, ar=32000 (GPT-SoVITS v1 default), ac=1
    # è¾“å‡º: adts AAC
    cmd = [
        "ffmpeg", 
        "-f", "s16le", 
        "-ar", str(sample_rate), 
        "-ac", "1", 
        "-i", "pipe:0", 
        "-c:a", "aac", 
        "-b:a", "128k", 
        "-f", "adts", 
        "pipe:1"
    ]
    
    logger.info(f"[Transcoder] Starting FFmpeg: {' '.join(cmd)}")
    process = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE, # æ•è·é”™è¯¯æ—¥å¿—
        bufsize=0 #Unbuffered
    )

    loop = asyncio.get_event_loop()
    
    # å¼‚æ­¥å†™å…¥ä»»åŠ¡
    async def writer():
        try:
            async for chunk in pcm_iterator:
                if chunk:
                    # ä½¿ç”¨ run_in_executor é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                    await loop.run_in_executor(None, process.stdin.write, chunk)
                    # flush ç¡®ä¿æ•°æ®ç«‹å³é€å…¥ ffmpeg
                    await loop.run_in_executor(None, process.stdin.flush) 
        except Exception as e:
            logger.error(f"[Transcoder] Writer error: {e}")
        finally:
            try:
                await loop.run_in_executor(None, process.stdin.close)
            except:
                pass
            logger.debug(f"[Transcoder] Writer task finished")

    # å¯åŠ¨å†™å…¥çº¿ç¨‹
    writer_task = asyncio.create_task(writer())
    
    # è¯»å–è¾“å‡ºå¹¶ yield
    try:
        # æŒç»­è¯»å–ç›´åˆ° stderr æç¤ºç»“æŸæˆ– stdout å…³é—­
        while True:
            # æ¯æ¬¡è¯»å– 4KB (AAC frame size usually smaller, but buffer safe)
            chunk = await loop.run_in_executor(None, process.stdout.read, 4096)
            if not chunk:
                break
            yield chunk
    except Exception as e:
        logger.error(f"[Transcoder] Reader error: {e}")
    finally:
        # âš¡ ä¿®å¤: åŠ å¼ºè¿›ç¨‹æ¸…ç†ï¼Œé˜²æ­¢åƒµå°¸è¿›ç¨‹
        try:
            writer_task.cancel()
            await asyncio.wait_for(writer_task, timeout=1.0)
        except (asyncio.CancelledError, asyncio.TimeoutError):
            pass
        
        # å¼ºåˆ¶æ¸…ç† FFmpeg è¿›ç¨‹
        try:
            if process.stdout: process.stdout.close()
            if process.stderr: process.stderr.close()
            
            # å…ˆå°è¯•æ­£å¸¸ç»ˆæ­¢
            process.terminate()
            try:
                await asyncio.wait_for(asyncio.to_thread(process.wait), timeout=2.0)
                logger.info("[Transcoder] FFmpeg terminated gracefully")
            except asyncio.TimeoutError:
                # è¶…æ—¶åˆ™å¼ºåˆ¶æ€æ­»
                logger.warning("[Transcoder] FFmpeg not responding, force killing...")
                process.kill()
                await asyncio.to_thread(process.wait)
                logger.warning("[Transcoder] FFmpeg force killed")
        except Exception as e:
            logger.error(f"[Transcoder] Cleanup error: {e}")


@app.post("/tts/synthesize")
async def synthesize_speech(request: TTSRequest):
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="Text cannot be empty")
    
    clean_text, detected_emotion = parse_emotion_tags(request.text)
    emotion_tag = detected_emotion or request.emotion
    
    # === GPT-SoVITS ===
    if request.engine == "gpt-sovits":
        if not gpt_sovits_engine:
             raise HTTPException(status_code=500, detail="GPT-SoVITS engine not loaded")
        
        try:
            ref_audio_path, ref_text, ref_lang = gpt_sovits_engine.get_ref_audio(request.voice, emotion_tag)
            # âš¡ Fallback Check: Ensure service is actually online before trying to stream
            if not gpt_sovits_engine.is_available:
                gpt_sovits_engine.check_connection() # Last ditch check
                if not gpt_sovits_engine.is_available:
                     raise Exception("Service is marked offline (is_available=False)")

            text_lang = gpt_sovits_engine.detect_language(clean_text)
            
            if not ref_audio_path:
                 raise Exception("Reference audio lookup failed")

            # âš¡ å…³é”®æ”¹åŠ¨: è¯·æ±‚ RAW (PCM) æ ¼å¼ï¼Œé¿å… Server ç«¯ FFmpeg ä½æ•ˆ
            # â­ ä¼˜åŒ–: æ·»åŠ  text_split_method='cut5' (æŒ‰æ ‡ç‚¹åˆ‡åˆ†) åŠ é€Ÿé¦–å­—ç”Ÿæˆ
            # âš¡ ä¼˜åŒ–: æ·»åŠ æ¨¡å‹ç¼“å­˜å‚æ•°ï¼Œå¤ç”¨ speaker embedding å‡å°‘é¦–å­—å»¶è¿Ÿ
            params = {
                "text": clean_text,
                "text_lang": text_lang,
                "ref_audio_path": ref_audio_path,
                "prompt_text": ref_text,
                "prompt_lang": ref_lang,
                "media_type": "raw", # è¯·æ±‚ PCM Raw Data
                "streaming_mode": "true",
                "text_split_method": "cut5", # ä¼˜åŒ–: æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                "batch_size": 1,             # ä¼˜åŒ–: å¼ºåˆ¶ batch_size=1
                "parallel_infer": True,      # ä¼˜åŒ–: å°è¯•å¼€å¯å¹¶è¡Œæ¨ç†
                # âš¡ æ–°å¢: æ¨¡å‹ç¼“å­˜å‚æ•°ï¼ˆå¦‚æœ GPT-SoVITS API æ”¯æŒï¼‰
                "use_cache": True,           # å¯ç”¨ speaker embedding ç¼“å­˜
                "cache_mode": "full"         # å®Œæ•´ç¼“å­˜æ¨¡å¼
            }
            
            target_url = f"{gpt_sovits_engine.api_url}/tts"

            async def raw_stream_generator():
                # å¤ç”¨å…¨å±€ http_client
                client = http_client
                if not client:
                    logger.warning("[TTS] Global HTTP client not available, ensuring fallback??")
                    # Should not facilitate fallback here, startup should guarantee it.
                    # Creating temporary for safety if logic fails but ideally shouldn't happen.
                    async with httpx.AsyncClient() as temp_client:
                         async for chunk in stream_request(temp_client, target_url, params):
                             yield chunk
                    return

                async for chunk in stream_request(client, target_url, params):
                    yield chunk

            async def stream_request(client, url, params):
                start_time = time.time()
                logger.info(f"[TTS] Upstream Request: {url} (RAW) | Split: cut5")
                
                try:
                    # âš¡ ä¿®å¤: æ·»åŠ è¯·æ±‚è¶…æ—¶ä¿æŠ¤ (60ç§’è¶…æ—¶)
                    timeout_config = httpx.Timeout(60.0, connect=10.0, read=60.0)
                    async with client.stream("GET", url, params=params, timeout=timeout_config) as response:
                        if response.status_code != 200:
                            error_text = await response.aread()
                            logger.error(f"GPT-SoVITS API Error: {response.status_code} {error_text}")
                            return
                        
                        first_byte_time = 0
                        chunk_count = 0
                        
                        async for chunk in response.aiter_bytes(chunk_size=4096):
                            cur_time = time.time()
                            if chunk_count == 0:
                                first_byte_time = cur_time
                                logger.info(f"[TTS-RAW] ğŸŸ¢ First Byte: {first_byte_time - start_time:.4f}s")
                            yield chunk
                            chunk_count += 1
                        
                        # âš¡ ä¿®å¤: ç¡®ä¿å“åº”å®Œå…¨æ¶ˆè´¹
                        logger.info(f"[TTS] Stream completed: {chunk_count} chunks")
                            
                except asyncio.TimeoutError:
                    logger.error(f"[TTS] Request timeout after 60s")
                except Exception as e:
                    logger.error(f"[TTS] Upstream connection failed: {e}")
            
            # ä½¿ç”¨æœ¬åœ° FFmpeg è½¬ç ä¸º AAC
            # æ³¨æ„: GPT-SoVITS v2 é»˜è®¤é‡‡æ ·ç‡å¯èƒ½æ˜¯ 32000ï¼Œéœ€ç¡®è®¤
            # å¦‚æœå£°éŸ³å˜å¿«æˆ–å˜æ…¢ï¼Œè°ƒæ•´ sample_rate
            aac_stream = transcode_to_aac(raw_stream_generator(), sample_rate=32000)
            
            return StreamingResponse(aac_stream, media_type="audio/aac")
            
        except Exception as e:
            logger.error(f"GPT-SoVITS Error: {e}")
            logger.warning("Falling back to Edge TTS...")

    # === Edge TTS (Fallback) ===
    # âš ï¸ æ³¨æ„ï¼šEdge TTS å…è´¹ç‰ˆä¸æ”¯æŒ <mstts:express-as> æƒ…æ„Ÿæ ·å¼
    # ä»¥ä¸‹ emotion_style_map é€»è¾‘ä»…ä¸ºæ¥å£é¢„ç•™ï¼Œå®é™…è¾“å‡ºä¸ºçº¯æ–‡æœ¬åˆæˆ
    # è‹¥éœ€å¯ç”¨æƒ…æ„Ÿæ ·å¼ï¼Œéœ€æ›¿æ¢ä¸º Azure Cognitive Services Speech SDKï¼ˆä»˜è´¹æœåŠ¡ï¼‰
    if edge_tts_engine is None:
        raise HTTPException(status_code=500, detail="Edge TTS engine not initialized")
        
    target_voice = request.voice
    if request.engine == "gpt-sovits":
        target_voice = "zh-CN-XiaoxiaoNeural"
        
    edge_style = emotion_style_map.get(emotion_tag.lower()) if emotion_tag else None
    logger.info(f"[TTS] Fallback Edge TTS: '{clean_text[:10]}...'")
    
    try:
        # Use clean_text directly. edge_tts will handle it.
        communicate = edge_tts_engine.Communicate(clean_text, target_voice)
        stream_iterator = communicate.stream().__aiter__()
        
        async def edge_stream_generator():
            try:
                async for chunk in stream_iterator:
                    if chunk["type"] == "audio":
                        yield chunk["data"]
            except Exception as e:
                logger.error(f"[EdgeTTS] Stream error: {e}")

        return StreamingResponse(edge_stream_generator(), media_type="audio/mpeg")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/tts/voices")
async def list_voices(engine: str = "edge-tts"):
    if engine == "gpt-sovits":
        if gpt_sovits_engine: return {"voices": gpt_sovits_engine.list_voices()}
        return {"voices": [], "error": "GPT-SoVITS not loaded"}
    if edge_tts_engine:
        try:
            voices = await edge_tts_engine.list_voices()
            zh = [v for v in voices if v["Locale"].startswith("zh-")]
            en = [v for v in voices if v["Locale"].startswith("en-")]
            return {"chinese": [{"name": v["ShortName"], "gender": v["Gender"]} for v in zh], "english": [{"name": v["ShortName"], "gender": v["Gender"]} for v in en]}
        except: return {"error": "Failed to list voices"}
    return {"error": "Engine not ready"}

@app.get("/tts/emotions")
async def list_emotions():
    """åˆ—å‡ºæƒ…æ„Ÿæ ·å¼æ˜ å°„è¡¨ï¼ˆä»…ä¾›å‚è€ƒï¼ŒEdge TTS å…è´¹ç‰ˆä¸æ”¯æŒï¼‰"""
    return {
        "engine": "Edge TTS",
        "emotions": emotion_style_map,
        "warning": "Edge TTS å…è´¹ç‰ˆä¸æ”¯æŒæƒ…æ„Ÿæ ·å¼ã€‚è‹¥éœ€å¯ç”¨ï¼Œè¯·ä½¿ç”¨ Azure Cognitive Services æˆ– GPT-SoVITS å¼•æ“ã€‚",
        "supported_engines": {
            "edge-tts": "ä¸æ”¯æŒæƒ…æ„Ÿï¼ˆä»…å ä½ï¼‰",
            "gpt-sovits": "é€šè¿‡å‚è€ƒéŸ³é¢‘æ”¯æŒæƒ…æ„Ÿå…‹éš†"
        }
    }

@app.get("/health")
async def health_check():
    engines = []
    if edge_tts_engine: engines.append("Edge TTS")
    if gpt_sovits_engine:
        # Re-check status on health call (lazy check) or trust the init flag?
        # Trust flag but maybe trigger re-check if user asks? 
        # For now, just check the flag we set on init.
        if gpt_sovits_engine.is_available:
            engines.append("GPT-SoVITS")
        else:
             # Try one more time just in case it came online late
             gpt_sovits_engine.check_connection()
             if gpt_sovits_engine.is_available:
                 engines.append("GPT-SoVITS")
             
    return {"status": "ok", "active_engines": engines}

if __name__ == "__main__":
    import uvicorn
    from app_config import config
    uvicorn.run(app, host=config.network.host, port=config.network.tts_port, log_level="info")
