"""
TTS Server - æµå¼è¯­éŸ³åˆæˆæœåŠ¡
æ”¯æŒå¯æ’æ‹”çš„ TTS å¼•æ“ï¼ˆEdge TTS ä¸ºé»˜è®¤å®ç°ï¼‰
"""
import logging
import json
import re
import os
import time
import asyncio
import subprocess
from typing import Optional, AsyncGenerator
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import httpx

# å¯¼å…¥æœ¬åœ°æ¨¡å—
try:
    from tts_engine_gptsovits import GPTSoVITSEngine
except ImportError:
    from .tts_engine_gptsovits import GPTSoVITSEngine

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç¡®ä¿ FFmpeg (åœ¨ GPT-SoVITS/runtime) åœ¨ PATH ä¸­
def ensure_ffmpeg_path():
    # å‡è®¾ runtime åœ¨ä¸¤çº§ç›®å½•ä¸‹ (ä» python_backend å‘ä¸Š)
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    ffmpeg_dir = os.path.join(base_dir, "GPT-SoVITS", "runtime")
    if os.path.exists(ffmpeg_dir):
        path = os.environ.get("PATH", "")
        if ffmpeg_dir not in path:
            logger.info(f"Adding FFmpeg to PATH: {ffmpeg_dir}")
            os.environ["PATH"] = f"{ffmpeg_dir};{path}"
    else:
        logger.warning(f"FFmpeg binary directory not found at: {ffmpeg_dir}")

ensure_ffmpeg_path()

app = FastAPI(title="Lumina TTS Service")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

edge_tts_engine: Optional[any] = None
gpt_sovits_engine: Optional[any] = None
emotion_style_map = {}

class TTSRequest(BaseModel):
    text: str
    voice: str = "zh-CN-XiaoxiaoNeural"
    emotion: Optional[str] = None
    engine: str = "edge-tts"
    rate: str = "+0%"
    pitch: str = "+0Hz"


# å…¨å±€ HTTP å®¢æˆ·ç«¯ (è¿æ¥å¤ç”¨)
http_client: Optional[httpx.AsyncClient] = None

@app.on_event("startup")
async def startup_event():
    global edge_tts_engine, gpt_sovits_engine, emotion_style_map, http_client
    
    # åˆå§‹åŒ– HTTP å®¢æˆ·ç«¯
    http_client = httpx.AsyncClient(timeout=None) # ä¿æŒé•¿è¿æ¥
    logger.info("Shared HTTP client initialized")

    logger.info("Initializing Edge TTS...")
    try:
        import edge_tts
        edge_tts_engine = edge_tts
    except ImportError:
        logger.error("edge-tts not installed")
    
    logger.info("Initializing GPT-SoVITS...")
    try:
        gpt_sovits_engine = GPTSoVITSEngine()
        logger.info(f"GPT-SoVITS wrapper loaded")
    except Exception as e:
        logger.warning(f"Failed to load GPT-SoVITS wrapper: {e}")

    try:
        map_path = os.path.join(os.path.dirname(__file__), "tts_emotion_styles.json")
        if os.path.exists(map_path):
            with open(map_path, "r", encoding="utf-8") as f:
                emotion_style_map = json.load(f)
        else:
            emotion_style_map = {}
    except Exception as e:
        logger.warning(f"Failed to load emotion map: {e}")
        emotion_style_map = {}

@app.on_event("shutdown")
async def shutdown_event():
    global http_client
    if http_client:
        await http_client.aclose()
        logger.info("Shared HTTP client closed")
    # Clean up subprocesses if any (handled by their own logic usually)

def parse_emotion_tags(text: str):
    match = re.search(r"^\[([a-zA-Z]+)\]", text.strip())
    if match:
        emotion = match.group(1)
        clean_text = re.sub(r"^\[([a-zA-Z]+)\]", "", text.strip()).strip()
        return clean_text, emotion
    return text, None

def wrap_with_ssml(text: str, voice: str, style: str = None):
    """
    ç”Ÿæˆ SSML (Speech Synthesis Markup Language)
    
    æ³¨æ„ï¼šstyle å‚æ•°ä»…é€‚ç”¨äº Azure Cognitive Services
    Edge TTS å…è´¹ç‰ˆä¼šå¿½ç•¥ <mstts:express-as> æ ‡ç­¾
    """
    safe_text = text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    if style:  # æ­¤åˆ†æ”¯åœ¨ Edge TTS ä¸‹æ— æ•ˆï¼Œä¿ç•™ä»…ä¸ºå…¼å®¹æ€§
        return f"""<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='https://www.w3.org/2001/mstts' xml:lang='en-US'>
    <voice name='{voice}'>
        <mstts:express-as style='{style}'>
            {safe_text}
        </mstts:express-as>
    </voice>
</speak>"""
    return f"""<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-US'>
    <voice name='{voice}'>
        {safe_text}
    </voice>
</speak>"""

async def transcode_to_aac(pcm_iterator: AsyncGenerator[bytes, None], sample_rate=32000) -> AsyncGenerator[bytes, None]:
    """
    æµå¼è½¬ç : PCM (Stream) -> FFmpeg -> AAC (Stream)
    """
    # å¯åŠ¨ FFmpeg è¿›ç¨‹
    # è¾“å…¥: s16le PCM, ar=32000 (GPT-SoVITS v1 default), ac=1
    # è¾“å‡º: adts AAC
    cmd = [
        "ffmpeg", 
        "-f", "s16le", 
        "-ar", str(sample_rate), 
        "-ac", "1", 
        "-i", "pipe:0", 
        "-c:a", "aac", 
        "-b:a", "128k", 
        "-f", "adts", 
        "pipe:1"
    ]
    
    logger.info(f"[Transcoder] Starting FFmpeg: {' '.join(cmd)}")
    process = subprocess.Popen(
        cmd,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE, # æ•è·é”™è¯¯æ—¥å¿—
        bufsize=0 #Unbuffered
    )

    loop = asyncio.get_event_loop()
    
    # å¼‚æ­¥å†™å…¥ä»»åŠ¡
    async def writer():
        try:
            async for chunk in pcm_iterator:
                if chunk:
                    # ä½¿ç”¨ run_in_executor é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                    await loop.run_in_executor(None, process.stdin.write, chunk)
                    # flush ç¡®ä¿æ•°æ®ç«‹å³é€å…¥ ffmpeg (å½±å“ä¸å¤§ä½†ä»¥é˜²ä¸‡ä¸€)
                    await loop.run_in_executor(None, process.stdin.flush) 
        except Exception as e:
            logger.error(f"[Transcoder] Writer error: {e}")
        finally:
            try:
                await loop.run_in_executor(None, process.stdin.close)
            except:
                pass

    # å¯åŠ¨å†™å…¥çº¿ç¨‹
    writer_task = asyncio.create_task(writer())
    
    # è¯»å–è¾“å‡ºå¹¶ yield
    try:
        # æŒç»­è¯»å–ç›´åˆ° stderr æç¤ºç»“æŸæˆ– stdout å…³é—­
        while True:
            # æ¯æ¬¡è¯»å– 4KB (AAC frame size usually smaller, but buffer safe)
            chunk = await loop.run_in_executor(None, process.stdout.read, 4096)
            if not chunk:
                break
            yield chunk
    except Exception as e:
        logger.error(f"[Transcoder] Reader error: {e}")
    finally:
        # æ¸…ç†
        writer_task.cancel()
        if process.stdout: process.stdout.close()
        if process.stderr: process.stderr.close()
        process.terminate()
        logger.info("[Transcoder] FFmpeg terminated")


@app.post("/tts/synthesize")
async def synthesize_speech(request: TTSRequest):
    if not request.text.strip():
        raise HTTPException(status_code=400, detail="Text cannot be empty")
    
    clean_text, detected_emotion = parse_emotion_tags(request.text)
    emotion_tag = detected_emotion or request.emotion
    
    # === GPT-SoVITS ===
    if request.engine == "gpt-sovits":
        if not gpt_sovits_engine:
             raise HTTPException(status_code=500, detail="GPT-SoVITS engine not loaded")
        
        try:
            ref_audio_path, ref_text, ref_lang = gpt_sovits_engine.get_ref_audio(request.voice, emotion_tag)
            text_lang = gpt_sovits_engine.detect_language(clean_text)
            
            if not ref_audio_path:
                 raise Exception("Reference audio lookup failed")

            # âš¡ å…³é”®æ”¹åŠ¨: è¯·æ±‚ RAW (PCM) æ ¼å¼ï¼Œé¿å… Server ç«¯ FFmpeg ä½æ•ˆ
            # â­ ä¼˜åŒ–: æ·»åŠ  text_split_method='cut5' (æŒ‰æ ‡ç‚¹åˆ‡åˆ†) åŠ é€Ÿé¦–å­—ç”Ÿæˆ
            params = {
                "text": clean_text,
                "text_lang": text_lang,
                "ref_audio_path": ref_audio_path,
                "prompt_text": ref_text,
                "prompt_lang": ref_lang,
                "media_type": "raw", # è¯·æ±‚ PCM Raw Data
                "streaming_mode": "true",
                "text_split_method": "cut5", # ä¼˜åŒ–: æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†
                "batch_size": 1,             # ä¼˜åŒ–: å¼ºåˆ¶ batch_size=1
                "parallel_infer": True       # ä¼˜åŒ–: å°è¯•å¼€å¯å¹¶è¡Œæ¨ç†
            }
            
            target_url = f"{gpt_sovits_engine.api_url}/tts"

            async def raw_stream_generator():
                # å¤ç”¨å…¨å±€ http_client
                client = http_client
                if not client:
                    logger.warning("[TTS] Global HTTP client not available, ensuring fallback??")
                    # Should not facilitate fallback here, startup should guarantee it.
                    # Creating temporary for safety if logic fails but ideally shouldn't happen.
                    async with httpx.AsyncClient() as temp_client:
                         async for chunk in stream_request(temp_client, target_url, params):
                             yield chunk
                    return

                async for chunk in stream_request(client, target_url, params):
                    yield chunk

            async def stream_request(client, url, params):
                start_time = time.time()
                logger.info(f"[TTS] Upstream Request: {url} (RAW) | Split: cut5")
                
                try:
                    # ä½¿ç”¨ client.stream ä¿æŒè¿æ¥å¤ç”¨
                    async with client.stream("GET", url, params=params, timeout=60.0) as response:
                        if response.status_code != 200:
                            error_text = await response.aread()
                            logger.error(f"GPT-SoVITS API Error: {response.status_code} {error_text}")
                            return
                        
                        first_byte_time = 0
                        chunk_count = 0
                        
                        async for chunk in response.aiter_bytes(chunk_size=4096):
                            cur_time = time.time()
                            if chunk_count == 0:
                                first_byte_time = cur_time
                                logger.info(f"[TTS-RAW] ğŸŸ¢ First Byte: {first_byte_time - start_time:.4f}s")
                            yield chunk
                            chunk_count += 1
                            
                except Exception as e:
                    logger.error(f"[TTS] Upstream connection failed: {e}")
            
            # ä½¿ç”¨æœ¬åœ° FFmpeg è½¬ç ä¸º AAC
            # æ³¨æ„: GPT-SoVITS v2 é»˜è®¤é‡‡æ ·ç‡å¯èƒ½æ˜¯ 32000ï¼Œéœ€ç¡®è®¤
            # å¦‚æœå£°éŸ³å˜å¿«æˆ–å˜æ…¢ï¼Œè°ƒæ•´ sample_rate
            aac_stream = transcode_to_aac(raw_stream_generator(), sample_rate=32000)
            
            return StreamingResponse(aac_stream, media_type="audio/aac")
            
        except Exception as e:
            logger.error(f"GPT-SoVITS Error: {e}")
            logger.warning("Falling back to Edge TTS...")

    # === Edge TTS (Fallback) ===
    # âš ï¸ æ³¨æ„ï¼šEdge TTS å…è´¹ç‰ˆä¸æ”¯æŒ <mstts:express-as> æƒ…æ„Ÿæ ·å¼
    # ä»¥ä¸‹ emotion_style_map é€»è¾‘ä»…ä¸ºæ¥å£é¢„ç•™ï¼Œå®é™…è¾“å‡ºä¸ºçº¯æ–‡æœ¬åˆæˆ
    # è‹¥éœ€å¯ç”¨æƒ…æ„Ÿæ ·å¼ï¼Œéœ€æ›¿æ¢ä¸º Azure Cognitive Services Speech SDKï¼ˆä»˜è´¹æœåŠ¡ï¼‰
    if edge_tts_engine is None:
        raise HTTPException(status_code=500, detail="Edge TTS engine not initialized")
        
    target_voice = request.voice
    if request.engine == "gpt-sovits":
        target_voice = "zh-CN-XiaoxiaoNeural"
        
    edge_style = emotion_style_map.get(emotion_tag.lower()) if emotion_tag else None
    ssml_text = wrap_with_ssml(clean_text, target_voice, edge_style)  # style å‚æ•°å½“å‰æ— æ•ˆ
    logger.info(f"[TTS] Fallback Edge TTS: '{clean_text[:10]}...'")
    
    try:
        communicate = edge_tts_engine.Communicate(ssml_text, target_voice)
        stream_iterator = communicate.stream().__aiter__()
        
        async def edge_stream_generator():
            try:
                async for chunk in stream_iterator:
                    if chunk["type"] == "audio":
                        yield chunk["data"]
            except Exception as e:
                logger.error(f"[EdgeTTS] Stream error: {e}")

        return StreamingResponse(edge_stream_generator(), media_type="audio/mpeg")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/tts/voices")
async def list_voices(engine: str = "edge-tts"):
    if engine == "gpt-sovits":
        if gpt_sovits_engine: return {"voices": gpt_sovits_engine.list_voices()}
        return {"voices": [], "error": "GPT-SoVITS not loaded"}
    if edge_tts_engine:
        try:
            voices = await edge_tts_engine.list_voices()
            zh = [v for v in voices if v["Locale"].startswith("zh-")]
            en = [v for v in voices if v["Locale"].startswith("en-")]
            return {"chinese": [{"name": v["ShortName"], "gender": v["Gender"]} for v in zh], "english": [{"name": v["ShortName"], "gender": v["Gender"]} for v in en]}
        except: return {"error": "Failed to list voices"}
    return {"error": "Engine not ready"}

@app.get("/tts/emotions")
async def list_emotions():
    """åˆ—å‡ºæƒ…æ„Ÿæ ·å¼æ˜ å°„è¡¨ï¼ˆä»…ä¾›å‚è€ƒï¼ŒEdge TTS å…è´¹ç‰ˆä¸æ”¯æŒï¼‰"""
    return {
        "engine": "Edge TTS",
        "emotions": emotion_style_map,
        "warning": "Edge TTS å…è´¹ç‰ˆä¸æ”¯æŒæƒ…æ„Ÿæ ·å¼ã€‚è‹¥éœ€å¯ç”¨ï¼Œè¯·ä½¿ç”¨ Azure Cognitive Services æˆ– GPT-SoVITS å¼•æ“ã€‚",
        "supported_engines": {
            "edge-tts": "ä¸æ”¯æŒæƒ…æ„Ÿï¼ˆä»…å ä½ï¼‰",
            "gpt-sovits": "é€šè¿‡å‚è€ƒéŸ³é¢‘æ”¯æŒæƒ…æ„Ÿå…‹éš†"
        }
    }

@app.get("/health")
async def health_check():
    engines = []
    if edge_tts_engine: engines.append("Edge TTS")
    if gpt_sovits_engine: engines.append("GPT-SoVITS")
    return {"status": "ok", "active_engines": engines}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8766, log_level="info")
